{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jovyan/.cache/pip/wheels/dc/1e/39/2ba6727a70902a872b0c391fd2d5a72a111a5295e29c0f0bcd/textgenrnn-2.0.0-py3-none-any.whl\n",
      "Collecting h5py\n",
      "  Using cached h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "Collecting tensorflow>=2.1.0\n",
      "  Using cached tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8 MB)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /opt/conda/lib/python3.6/site-packages (from textgenrnn) (0.20.2)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /home/jovyan/.local/lib/python3.6/site-packages (from textgenrnn) (4.41.1)\n",
      "Collecting keras\n",
      "  Using cached Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /opt/conda/lib/python3.6/site-packages (from h5py->textgenrnn) (1.15.4)\n",
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.6/site-packages (from h5py->textgenrnn) (1.14.0)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Using cached tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "Collecting astor>=0.6.0\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow>=2.1.0->textgenrnn) (3.11.3)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Using cached tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /home/jovyan/.local/lib/python3.6/site-packages (from tensorflow>=2.1.0->textgenrnn) (0.9.0)\n",
      "Processing /home/jovyan/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd/gast-0.2.2-cp36-none-any.whl\n",
      "Processing /home/jovyan/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6/termcolor-1.1.0-cp36-none-any.whl\n",
      "Collecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Using cached scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.6/site-packages (from tensorflow>=2.1.0->textgenrnn) (0.34.2)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /home/jovyan/.local/lib/python3.6/site-packages (from tensorflow>=2.1.0->textgenrnn) (1.27.2)\n",
      "Collecting keras-preprocessing>=1.1.0\n",
      "  Using cached Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.2.0-py3-none-any.whl (63 kB)\n",
      "Processing /home/jovyan/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63/wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl\n",
      "Processing /home/jovyan/.cache/pip/wheels/e5/9d/ad/2ee53cf262cba1ffd8afe1487eef788ea3f260b7e6232a80fc/PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /home/jovyan/.local/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (1.11.3)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/jovyan/.local/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (3.2.1)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/jovyan/.local/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (46.0.0.post20200311)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /home/jovyan/.local/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (1.25.7)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /home/jovyan/.local/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /opt/conda/lib/python3.6/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow>=2.1.0->textgenrnn) (0.4.8)\n",
      "\u001b[31mERROR: tensorflow 2.1.0 has requirement numpy<2.0,>=1.16.0, but you'll have numpy 1.15.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: h5py, tensorboard, astor, tensorflow-estimator, gast, termcolor, scipy, keras-applications, keras-preprocessing, google-pasta, opt-einsum, wrapt, tensorflow, pyyaml, keras, textgenrnn\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.1.0\n",
      "    Uninstalling scipy-1.1.0:\n",
      "      Successfully uninstalled scipy-1.1.0\n",
      "Successfully installed astor-0.8.1 gast-0.2.2 google-pasta-0.2.0 h5py-2.10.0 keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.0 opt-einsum-3.2.0 pyyaml-5.3.1 scipy-1.4.1 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0 textgenrnn-2.0.0 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U textgenrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train new model - char embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgen_word = textgenrnn(name=\"word_level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236 texts collected.\n",
      "Training new model w/ 2-layer, 128-cell Bidirectional LSTMs\n",
      "Training on 87,037 word sequences.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 679 steps\n",
      "Epoch 1/100\n",
      "679/679 [==============================] - 50s 73ms/step - loss: 5.4349\n",
      "Epoch 2/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 4.3741\n",
      "Epoch 3/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 3.7473\n",
      "Epoch 4/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 3.1903\n",
      "Epoch 5/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 2.6634\n",
      "Epoch 6/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 2.1429\n",
      "Epoch 7/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 1.6901\n",
      "Epoch 8/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 1.3404\n",
      "Epoch 9/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 1.0623\n",
      "Epoch 10/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 0.8416\n",
      "Epoch 11/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 0.6909\n",
      "Epoch 12/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 0.5723\n",
      "Epoch 13/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 0.4658\n",
      "Epoch 14/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 0.4350\n",
      "Epoch 15/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 0.4033\n",
      "Epoch 16/100\n",
      "679/679 [==============================] - 42s 63ms/step - loss: 0.3472\n",
      "Epoch 17/100\n",
      "679/679 [==============================] - 42s 62ms/step - loss: 0.3197\n",
      "Epoch 18/100\n",
      "679/679 [==============================] - 42s 62ms/step - loss: 0.3109\n",
      "Epoch 19/100\n",
      "679/679 [==============================] - 42s 62ms/step - loss: 0.3085\n",
      "Epoch 20/100\n",
      "678/679 [============================>.] - ETA: 0s - loss: 0.2847####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "s ike s place -: i had to see what all the hype was about with ike's place since i have heard nothing but incredible things. i didn't feel like waiting in line so i decided to phone my order in but when the guy had the real tea here. i'm not going anywhere that requires a until may anyway. everything i enjoyed is worthy of my review! shoutout to the table who even the names of the ice cream flavors and you're done what. we did the end of a day but trust me. you will and now that your in. the cheese is served with a sweet liquid reminiscent of your college days (brown bag 40s and jello shots). d.) if you are a fan of deep fried bomb drunk being available to your under a table opens in a good thing. we were given 7: 30 pm which we took a little more elegant. the first time i had ordered 10 dishes. or basically what it was a good work for the next time because it was seared filet of the beef and a very fresh. tasty if you have large amount of food and water coming. (truly decadent?), and many unique flavors to sample - the meat was super tender and flavorful. the meat was super juicy and the skin was crispy. the chicken and the bacon wrapped enoki mushrooms (yelp. / photos /) this was super tasty. 4. best i've had and it absolutely amazing. sometimes simple! they actually had it on\n",
      "\n",
      "s ike s place -: i had to see what all the hype was about with ike's place since i have heard nothing but incredible things. i didn't feel like waiting in line so i decided to phone my order in but when the guy had the real tea here. i'm not going anywhere that requires a until may anyway. everything i enjoyed is worthy of my review! shoutout to the table who even the names of the ice cream flavors and a twinkle in their eye. for this time, and a free didn't matter. we were seated immediately greeted with and our drinks arrived quickly. apparently they don't expect to find the heavy side. though i wish you could order it as a starter it was or it. but if you want to yourself, you can also make it a more fusion experience if you select some of the day. - you can make a reservation. if you are coming from a (special). and you can't ask for a \"the tasting menu\". if you're what your secret?.. even if you are a man. \"with brenda's help, i to j.\" by butter \"started / s your,\" your made secret's that? i had a reservation for two. it's a man. / s\n",
      "\n",
      "s ike s place -: so what has changed in another city of prime for two years. something i want to fancy this and was a meal to be able to proceed to eat ice cream. i dig their. / s\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "s ike s place -: i had to see what to add a: i'd heard nothing but satisfying. there are three more types of that good asian of. - oh, and a - - i'm a filet mignon girl - - it still was delish) and very much passion. he made it with his husband and friends, he was two extremely helpful. we started with a cocktail of drinks with an evening like on the evening, and wine there was and cozy. fire was a nice mini - from the. thank you gary danko, i wondered if you must have been the dubbed \" who white shorts and cuts in the lounge they it. once we pick, our friend decided to do valet parking for which was a nice gesture by a little low restaurant. a first time around, here's what you get that. the staff is and a very staff will be through down the pictures of food. however, that does not take away from the flavor. and everything here is'. good vegetarian menu is. but since they de - bone the fish for you and i was already pretty stuffed we decided to split this dish. we chose the mediterranean sea bass. omg it was delicious. yes sea bass is very soft but a delicate oysters and - their roasted pumpkin - pancakes with pecan syrup, and extra creamy spinach, but not too pricey for ice cream, but not hot. pepper, real pastry? to the presentation of creamy sweet and corn. risotto with the creamy mashed potatoes\n",
      "\n",
      "s ike s place -: so what has changed in another city of new for izakaya sozai. i will not be to wait to on weekends, there are still reservations to be for a wait list. \" / s\n",
      "\n",
      "s house of prime rib: i'm not sure what hasn't been said about hopr, so i not tried this place sooner. a lot of times and we come here from. no, that's going to you up to the next couple of scores in to the - oh wait. i'd go to any on the other and super nice. i will come back except i very, and my casual meal, friends, i highly recommend this spot for a romantic date or a two of other people on the menu., it's a man what that you get. to. \" i'll get some of the greek yogurt and greek. anyways., finally! no to the wait, i had the restaurant to not be able to proceed with a corn. i really enjoyed this night! my friend misty had the secret breakfast and a scoop of the vietnamese coffee. 6 seemed a lot, but just inviting either. we did it? well, that! i am not craving it steak; however, was as i had the english cut). omg the meat. tender perfectly seared scallop with uni and duck, you will sure that's on this. the chicken itself is very flavorful and the rich butter always. i think still questions about the when dessert arrives, ask. - i have photos i will be to try some dishes that again! / s\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "s the front porch: i took my favorite yelp celebrity. i don't start if you're looking for a specific). a long line, i dont know what their right through my stomach for each four of us, and it made reservations. we no time, and picked the small order of the ca state bird with provisions (fried quail) and the small order of the glazed pork ribs with. then comes with the fun part of one dishes: the warm try out almost better than the amuse bouche. i will be back for that long, but also they had a vegan entree for a experience and the yorkshire pudding is! the fish and a cheese course for the price, we shared the velvet. red it had a million things in it, including cake,, panna cotta,, sorbet, a macaron, ice cream and cheese - a vanilla flavor but also good but definitely a must try it! the matcha affogato is also a must try! i also loved the mushrooms with the lettuce leaves tossed right on the inside. the chicken skin was so crispy and full of flavor. tasted like i was glad to hear them at 10 years ago, but i could have to pass on that next time and try the chicken sandwich. - next time, around, given that some bread were was a special, which i've had which had i split was the end of the meal. i noticed only knowing that i was actually impressed the end of the meal it was a. is given that,\n",
      "\n",
      "s state bird provisions: i went on a week at this night. i took my daughter after her dr.. i spent 4. 75). 75 on a double scoop of toffee coffee in a cup. she had the 3. 25 kid scoop and an almond combo. thought were very delicious! eaten with the coconut rice and rice the out of the desserts. we ordered the \"lunch\". in this case, it was well worth the - lobster risotto with the caviar. i ended up dipping my bread to it. who knew that i had a bit of sweetness, but i'd probably 20 choices but try some of the best dish i've ever had! looking at have the wonderful opportunity to say wow. - i could eat a when they come next to hit up and become. it's just how a good place this is the place where all they're all super small. but be sure to you have one watery eyes on the weekend. - ramen with pork belly and - beef filet - beef like. a filet mignon or, left us feeling full and i would get that. couldn't ever come to my. i don't think i can come back and often for salad! with only butter i wish you toast and jam. perhaps my but the rabbit is great too. i looked like at a couple dozen other steakhouses / meat, i've been done before, i was still hungry for the next level of what has the first thought went into the\n",
      "\n",
      "s the front porch: i took my favorite yelp celebrity here for fine dining. sadly, you dear me (: 1) i liked of. for coffee is a 6 months. / s\n",
      "\n",
      "679/679 [==============================] - 105s 155ms/step - loss: 0.2848\n",
      "Epoch 21/100\n",
      "679/679 [==============================] - 43s 63ms/step - loss: 0.2488\n",
      "Epoch 22/100\n",
      "679/679 [==============================] - 42s 62ms/step - loss: 0.2472\n",
      "Epoch 23/100\n",
      "679/679 [==============================] - 42s 62ms/step - loss: 0.2533\n",
      "Epoch 24/100\n",
      "679/679 [==============================] - 42s 62ms/step - loss: 0.2518\n",
      "Epoch 25/100\n",
      "679/679 [==============================] - 42s 62ms/step - loss: 0.2197\n",
      "Epoch 26/100\n",
      "679/679 [==============================] - 42s 62ms/step - loss: 0.2035\n",
      "Epoch 27/100\n",
      "679/679 [==============================] - 42s 62ms/step - loss: 0.1893\n",
      "Epoch 28/100\n",
      "679/679 [==============================] - 42s 62ms/step - loss: 0.1902\n",
      "Epoch 29/100\n",
      "679/679 [==============================] - 42s 62ms/step - loss: 0.1915\n",
      "Epoch 30/100\n",
      "679/679 [==============================] - 42s 62ms/step - loss: 0.1756\n",
      "Epoch 31/100\n",
      "679/679 [==============================] - 42s 62ms/step - loss: 0.1704\n",
      "Epoch 32/100\n",
      "679/679 [==============================] - 42s 62ms/step - loss: 0.1656\n",
      "Epoch 33/100\n",
      "496/679 [====================>.........] - ETA: 11s - loss: 0.1608"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8f372652b08e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                         \u001b[0mgen_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                         \u001b[0mword_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                         header=False)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/textgenrnn/textgenrnn.py\u001b[0m in \u001b[0;36mtrain_from_file\u001b[0;34m(self, file_path, header, delim, new_model, context, is_csv, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             self.train_new_model(\n\u001b[0;32m--> 365\u001b[0;31m                 texts, context_labels=context_labels, **kwargs)\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/textgenrnn/textgenrnn.py\u001b[0m in \u001b[0;36mtrain_new_model\u001b[0;34m(self, texts, context_labels, num_epochs, gen_epochs, batch_size, dropout, train_size, validation, save_epochs, multi_gpu, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m                             \u001b[0msave_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                             \u001b[0mmulti_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"textgenrnn_weights_saved.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/textgenrnn/textgenrnn.py\u001b[0m in \u001b[0;36mtrain_on_texts\u001b[0;34m(self, texts, context_labels, batch_size, num_epochs, verbose, new_model, gen_epochs, train_size, max_gen_length, validation, dropout, via_new_model, save_epochs, multi_gpu, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m                               \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m                               )\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_build_call_outputs\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m   1920\u001b[0m     \u001b[0;31m# Replace outputs with results, skipping over any 'None' values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1921\u001b[0m     outputs_list = nest.flatten(self._func_graph.structured_outputs,\n\u001b[0;32m-> 1922\u001b[0;31m                                 expand_composites=True)\n\u001b[0m\u001b[1;32m   1923\u001b[0m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mnest\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m   \"\"\"\n\u001b[0;32m--> 274\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "textgen_word.reset()\n",
    "textgen_word.train_from_file('../../data/clean_reviews.txt',\n",
    "                        new_model=True,\n",
    "                        rnn_bidirectional=True,\n",
    "                        rnn_size=128,\n",
    "                        rnn_layers=2,\n",
    "                        dim_embeddings=300,\n",
    "                        num_epochs=100,\n",
    "                        max_words=3000,\n",
    "                        gen_epochs=20,\n",
    "                        word_level=True,\n",
    "                        header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 300)      900600      input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (Bidirectional)           (None, 40, 256)      439296      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_2 (Bidirectional)           (None, 40, 256)      394240      rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_concat (Concatenate)        (None, 40, 812)      0           embedding[0][0]                  \n",
      "                                                                 rnn_1[0][0]                      \n",
      "                                                                 rnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention (AttentionWeightedAve (None, 812)          812         rnn_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 3002)         2440626     attention[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,175,574\n",
      "Trainable params: 4,175,574\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "textgen_word.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 300)      353400      input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (Bidirectional)           (None, 40, 512)      1140736     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_2 (Bidirectional)           (None, 40, 512)      1574912     rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_concat (Concatenate)        (None, 40, 1324)     0           embedding[0][0]                  \n",
      "                                                                 rnn_1[0][0]                      \n",
      "                                                                 rnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention (AttentionWeightedAve (None, 1324)         1324        rnn_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1178)         1560850     attention[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,631,222\n",
      "Trainable params: 4,631,222\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "textgen_word.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(12, 8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = [\n",
    "    4.7465,\n",
    "    4.4868,\n",
    "    4.0570,\n",
    "    3.5368,\n",
    "    2.9899,\n",
    "    2.4573,\n",
    "    2.0293,\n",
    "    1.4660,\n",
    "    1.0459,\n",
    "    0.6873,\n",
    "    0.4033,\n",
    "    0.2432,\n",
    "    0.1414,\n",
    "    0.1027,\n",
    "    0.0786,\n",
    "    0.0631,\n",
    "    0.0572,\n",
    "    0.0500,\n",
    "    0.0493,\n",
    "    0.0447\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss,  label='word-rnn')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload and generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from textgenrnn import textgenrnn\n",
    "\n",
    "weights_path = os.path.join(os.path.abspath(os.getcwd()), \"word_level_gary_danko_weights.hdf5\")\n",
    "config_path = os.path.join(os.path.abspath(os.getcwd()), \"word_level_gary_danko_config.json\")\n",
    "vocab_path = os.path.join(os.path.abspath(os.getcwd()), \"word_level_gary_danko_vocab.json\")\n",
    "\n",
    "textgen_word = textgenrnn(\n",
    "    config_path=config_path,\n",
    "    vocab_path=vocab_path,\n",
    "    weights_path=weights_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "< s > gary_danko: i'm drooling about the food while writing this review. my bf booked this for my first? i was totally impressed by the service, then some of the good - top 40s pop, and not even more delightful. the * pork chop was absolutely divine. it was served / slices of grilled summer peach, sauteed chard, & sweet corn. the meat was tender and perfect. slow and bites were to take in all that juicy flavorful meat. it paired perfectly / the peach & veggies. bottom line: say to my (old) favorite pork chop entree. you have been to squeeze the lemon on top and just enjoy my deliciousness. now, i'm not sure my friend - - house of prime rib with some cinnamon - taste, and cooked the right batter to ratio. the bacon wrapped mochi was a little. the mochi was chewy as expected, but lacked flavor which thankfully mr. instead of dr. pepper, but here would be perfect to eat as not the case please! our server highly recommended we order: fried apple pie /: * * as for * * as we were a fan of prime bone, kokkari (regular from an cheese selection, though. - amuse bouche sashimi bite - i wanted more! - beef short ribs - the meat was so soft and, seems to a way better in than their stuff), but i wished i i had wish the pasta in a winner, i was reading the good at hopr cooked (and also yelpers) to go back. / s\n",
      "\n",
      "< s > gary_danko: i love the concept of gary danko's tasting menu. you choose 3, 4, or 5 courses (priced at,, and) and from there, you can do that. rose wine - they only had one rose wine by the glass on the menu. it was also a rose wine from napa. it was tasty, great, private burmese in. i have my best in however bacon, i got the on it. the flavor was refreshing, and i was glad but i could stuff myself with the mixed seafood). the two desserts were definitely the best night! the chicken skin is so crispy, the chicken hearts and it'll be full. tip i wait in line for any relationship the;.) there was so away. i'm definitely going back to see the unicorn. besides, i had so much trouble deciding on which sandwich to order. i want to try as many as i can!, 2008 - i ordered the \"-\" on dutch crunch which had what i believe to be not one but two kinds of lean, high - quality salami, ike's yummy, perfectly cooked (not, not burnt) bacon, cheddar, lettuce, leaves, and creaminess that tastes absolutely amazing. don't believe me? order one and try it! and if you have no room. the waiter recommended spinach and i think everything we had dessert but bc it wasn't as good as well. the takoyaki had a of mini - pot with, and that was delicious. i don't like caramel so i that didn't know why the service was very close by friend. i wanted to eat a new location in the mission (that is) means that is. we say 5: 30 pm in the first time around the soma area and we was going to be running late about 15 minutes late and the lady was very nice about it and told us to call her, we made a reservation for 2 months ahead to see if any names had been before the making that while it discussed with the us with the caviar (with the no potatoes and the soft serve in a mini frying pan, it was. the only thing i've had is decent to delectable, including two kinds of fish carpaccio (yes, it's like, but a bit and with olive oil and some of arugula) that were both fabulously and yet rich in -. the entrees often include a which i find to be delicious. tip - and only order\n",
      "\n",
      "< s > gary_danko: i love the concept of gary danko's tasting menu. you choose 3, 4, or 5 courses (priced at,, and) and from there, you can do that. rose wine - they only had one rose wine by the glass on the menu. it was also a rose wine from napa. it was very tasty and the swiss and stilton butter are nice but just was not a fan of this dish. would not order again. after dinner: i requested a lyft and when it came license plate said'fresh'and it had dice in the five courses you may have thought this night was done but i thought \" nah, forget it, yo, to san! / s\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "< s > gary_danko: i love the concept of gary danko's tasting menu. you choose 3, 4, or 5 courses (priced at, and) and from a burma superstar already gets. my * / s\n",
      "\n",
      "< s > gary_danko: i love the concept of gary danko's tasting menu. you choose 3, 4, or 5 courses (priced at, and) and from there, you can choose whatever combination of appetizers, entrees, and desserts you like. - take public transportation and walk here so that you can thoroughly enjoy your ice cream and not about the dishes under their pancakes & toast, commandables, desserts, and drinks menu - like, literally, anyone, because you don't really have a designated server every other dish you order (called \"provisions\") will be brought around 15 on the. per person added (just the best which the) was delightful. meat and for the baked type of or some place. my mother was, who the best food in the \"; - yes! \" / s\n",
      "\n",
      "< s > gary_danko: i love the concept of gary danko's tasting menu. you choose 3, 4, or 5 courses (priced at,, and) and from there, you can do that. while i love, i can't make a reservation! / s\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "< s > gary_danko: i'm drooling about the food while writing this review with my count. i went for the first time i ever last night for my boyfriends birthday after trying to get a table and gave us a - sign across the. street metered, parking available for two! - gd + duck liver mousse that back to the online and the two desserts (that has a fresh lemon mousse from a candle to french laundry. / s\n",
      "\n",
      "< s > gary_danko: i love this place. authentic french bistro with a great neighborhood vibe and perfect date spot. came here for dinner on saturday during my visit for a izakaya sozai. speaking, i am the steak and egg on the lamb. two of palm made glasses with a sad thing that a lot of me (cue the mellow sounds of barry: \" you know. now that i know. ike's is playing on the second week. it's that all are in good with no sugar. pecan, and that's fine by me because i've been here, so he took it for the five. pieces of fried chicken and best in this and one of the best burgers around the.; -) nah, who am not a - - oh because's. a - salad - loved it! came with delicious & tomatoes & a 19 old - school special - amuse bouche (5. 00). this gave some jello as more than i would like this fish interesting if we did! thankfully, sauce - heavy creamy medium with something delicious. i enjoyed the vietnamese coffee. 6 seemed more light and super flavorful. the best to finish the two desserts! / s\n",
      "\n",
      "< s > gary_danko: gary danko is to the best restaurant i have've had 5 times, or if you want to walk in without a reservation? get seated! / s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen_word.generate_samples(prefix=\"<s>gary_danko: \", max_gen_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
